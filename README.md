# 25春季学期图班轮转项目 - 熊英飞老师组

本仓库是熊英飞老师组为 2025 年北京大学图灵班轮转设计的实践项目之一，主要涉及和大模型相关的程序优化技术。

如果在完成项目的过程中遇到了任何问题，请随时通过微信或者邮件 (zhaoyuwei@stu.pku.edu.cn) 与负责的同学联系。

## 项目概述

### 动机

程序优化的重要性，大模型的强大能力，所以用大模型来辅助完成程序优化任务。

### 主要构成

- part1：尝试使用 api 来调用大模型，了解 api 相关的设置。了解提示工程技术。
- part2：尝试使用大模型来完成给定的程序优化任务，在具体的任务上对比不同 prompt 的效果。
- part3：阅读相关论文，尝试复现其中的技术。
- part4（选做）：尝试组合不同论文中的技术，或改进现有技术，判断效果是否有所提升。

注意：part2 和 part3 的顺序不是固定的，可以交叉完成。

### 时间安排

考虑 part4：
- part1：1周
- part2：1周
- part3：1-2周
- part4：1-2周

不考虑 part4：
- part1：1周
- part2：2周
- part3：2周


## part 1

### 1.1

目前我们主要使用 OpenAI 以及 DeepSeek 的大模型（由于国内无法直接使用 OpenAI 的 api，所以我们使用 api 代理平台），具体网站如下：
- https://platform.closeai-asia.com
- https://platform.deepseek.com

参考以下资料了解如何通过 api 调用大模型以及相关的参数设置：
- https://openai.com/api
- https://api-docs.deepseek.com/zh-cn

主要的参数包括：
- system
- user
- temperature
- 概率

尝试编写脚本来通过 api 调用大模型，尝试调整输入的参数以及获取输出的各类信息。

### 1.2

编写脚本，在给定代码库以及 commit hash 后，自动获取 commit 中的所有信息。主要有以下两种思路：
- 如果 commit 集中来自于一个或多个代码库，可以考虑将整个代码库下载到本地，并且直接从 git 信息中获取需要的部分
- 如果 commit 分散在许多不同的代码库，可以考虑直接调用 GitHub api，获取对应的 commit 信息。GitHub api 有调用频率的限制，主要有以下几种解决方法。
    - 多注册几个账号获得更多的 key
    - 纯等待，每调用一次之后 sleep(n)
    - 改用第一种方法

### 1.3

参考以下资料了解提示工程技术：
- https://www.promptingguide.ai/zh



## part 2

给定一个task和一些prompt技术，尝试通过api调用大模型并完成程序优化。

任务：
- 判断一个commit是否为性能优化
    - 从代码库的git信息中直接获取commit信息
    - 使用不同的prompt让大模型给出答案
        - 如何让大模型只回答 true / false / unknown（在大模型不确定的时候就回答unknown）
        - 如何提高大模型的回答准确率
        - 是否有一些类型的任务大模型认为不是性能优化，但在人类判断的结果上属于性能优化？比如优化内存访问的效率
    - 提高大模型回答的置信度（选做）
        - 尝试获得输出token的置信度
        - 根据置信度判断，大模型是否在某些时刻实际上比较确定但回答了unknown，在某些时刻实际上不确定但回答了true/false
        - 如何优化上述问题
- 使用大模型尝试优化一段代码（某个commit中被优化的代码）
    - 在所有任务上给统一的命令
        - 一轮对话结束，直接和大模型说：请你分析以下代码中是否存在性能优化的可能，请给出三种可能的性能优化方式，并给出你的优化结果
            - 分析大模型给出的优化方式有哪些类型，是否有一些是我们不想要的（例如提升代码可读性、可维护性等），调整prompt来规避这些可能。
            - 判断大模型给出的优化是否是正确的方向，以及优化的结果是否保持语义不变并且有真正的性能提升。
        - 使用 CoT，引导大模型先阅读并理解给出的代码，然后分析有什么性能优化的机会，最后给出优化的结果。
    - 在prompt中加入针对该代码的一些提示（这里的提示只包含优化方向，不包含任何示例代码或者具体的修改方式）
        - 一轮对话结束，人工判断里面有哪些可能的性能优化，并直接告诉大模型请你重点考虑xx方面的优化
        - 使用 CoT，具体流程如上，但在大模型给出一些性能优化的方向之后，手动判断哪一种使我们最希望实现的，并引导大模型采用该种优化。
    - 判断优化后代码的正确性
        - 语义是否保持不变
            - 若代码库中包含 unit test，尝试运行
            - 人工判断
        - 是否真正实现了性能提升
            - 若代码库中包含 performance test，尝试运行
            - 人工判断

------- 可以在完成以上部分后先跳到 part3，阅读现有论文并有一定了解后，继续完成下面的部分 -------

- 在不同 commit 之间交叉对比，寻找共同点
    - 分析不同 commit 实现的优化类型
    - 寻找优化方向类似的 commit
    - 根据上述结果，尝试搭建一个简单的分类系统，例如性能优化可以根据目的分成优化时间复杂度 / 空间复杂度，每一个大类下可以继续细分。
- 根据上述构建的分类系统，涉及prompt引导大模型给出每个 commit 的具体分类
    - 例如可以按照树结构，一层层询问大模型，并逐渐确定 commit 具体实现的优化类型
- 根据具体分类，引导大模型实现优化
    - 搭建一个通用的 prompt 框架
    - 根据具体分类，在 prompt 中加入针对性的提示，具体有以下两种形式
        - 该优化方式的总结，例如将 A 替换成 B
        - 该类优化的一个或多个具体例子，例如一段现有的代码（包含 A）和对应的优化后代码（包含 B）




## part 3

给定一些现有工作，阅读论文，然后尝试复现其中的技术。

现有论文：
- 优化小规模代码（竞赛题） - 不是目前的主要方向，了解即可。PIE 和 SBLLM 是比较主要的论文。
    - PIE：https://arxiv.org/abs/2302.07867
    - Learning to Improve Code Efficiency：https://arxiv.org/abs/2208.05297
    - Supersonic：https://ieeexplore.ieee.org/abstract/document/10606318/
    - SBLLM：https://arxiv.org/abs/2408.12159
- 优化大规模代码 - 是目前的主要方向，以下是同一个作者的前后两篇连续的工作
    - DeepDev-PERF：https://dl.acm.org/doi/abs/10.1145/3540250.3549096
    - RAPGen：https://arxiv.org/abs/2306.17077

但目前想要复现可能还有一些额外的困难，例如 RAPGen 中需要构建知识库，就涉及到从 GitHub 爬所有相关的代码库，并在 commit 中筛选出所有实现了 api 替换的部分，需要调用程序分析工具等。并且 C# 的代码库数量较少，而 C/C++ 的代码库数量超级多。




## part 4（选做）

尝试组合不同论文中的技术，或改进现有技术，判断效果是否有所提升。


## TODO

- 完善动机部分
- 完善1.1的主要参数部分
- 完善api参考资料部分，例如给出OpenAI官方关于每个参数的具体页面
- 完善part2，例如给出具体用于优化的commit等
- 考虑将part2的后半段放到part4中
- 考虑增加优化算法题的路线，这样就分成两条路线，要不优化算法题，要不优化大规模代码库中的一个部分